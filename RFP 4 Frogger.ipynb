{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f7114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(5)\n",
      "Initial state structure: (array([[[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        ...,\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45]],\n",
      "\n",
      "       [[ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        ...,\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45]],\n",
      "\n",
      "       [[ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        ...,\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45],\n",
      "        [ 82, 126,  45]]], dtype=uint8), {'lives': 4, 'episode_frame_number': 0, 'frame_number': 0})\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Q-values: [[-0.02306722 -0.03624917  0.04777201  0.05542348 -0.11550644]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ewilliams2\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00566363 -0.02436418  0.04528935  0.06514134 -0.12771839]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ewilliams2\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.00195008 -0.01877591  0.03811887  0.07504021 -0.12121636]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00594883 -0.01964147  0.03163203  0.06006731 -0.12158228]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00103304 -0.0161205   0.02327538  0.05260275 -0.11171053]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.00813079 -0.02014377  0.03185378  0.04169306 -0.09810597]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.00155167 -0.02345909  0.02736447  0.05392828 -0.11104579]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.009611   -0.02195471  0.03110464  0.04336112 -0.10783419]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00896838 -0.02155874  0.0340513   0.04759772 -0.10983865]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00852286 -0.02582329  0.04459887  0.05025344 -0.09914972]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.01179877 -0.0253137   0.03312287  0.04214775 -0.08753643]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Q-values: [[-0.02401511 -0.03220276  0.02726642  0.03947254 -0.09204785]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.01825587 -0.0294141   0.02312558  0.04461467 -0.09894043]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.01946586 -0.01247996  0.0339007   0.03163934 -0.10251447]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00110761 -0.00670469  0.02427471  0.03289647 -0.08156835]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00165648 -0.03101834  0.02700616  0.03432993 -0.10402513]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00750291 -0.04063711  0.033725    0.02829665 -0.11112788]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02031529 -0.03249837  0.0386945   0.03184226 -0.12215414]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01642211 -0.02584406  0.01847854  0.03142648 -0.137853  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Q-values: [[-0.01918865 -0.03711794  0.02562863  0.04066062 -0.12819566]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02696444 -0.03968674  0.01908955  0.04996663 -0.11608963]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02418279 -0.04898759  0.0226925   0.0325583  -0.10774367]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03760021 -0.04055353  0.02239079  0.03075478 -0.10652866]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0215524  -0.04025763  0.02530346  0.02820274 -0.10722602]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.01888965 -0.04721763  0.03068632  0.01898803 -0.11463849]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03040164 -0.04108343  0.0247728   0.02707552 -0.12965474]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02313081 -0.03944003  0.02020321  0.03281308 -0.12025148]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02180834 -0.03282851  0.02359513  0.04046733 -0.11664673]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02036595 -0.04781894  0.03133411  0.05125686 -0.118102  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.02261519 -0.04729223  0.02541738  0.03705088 -0.10065669]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01682829 -0.03976551  0.02696436  0.03477042 -0.11063842]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.0132571  -0.03174257  0.02731738  0.03004125 -0.10068935]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02169521 -0.03625433  0.02759857  0.03207141 -0.09897474]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.01395183 -0.03974975  0.02952005  0.0336704  -0.09953266]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.007611   -0.03815887  0.03778566  0.04017142 -0.09545685]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00800505 -0.05049611  0.03058119  0.05436073 -0.10906259]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00647238 -0.03644963  0.02712285  0.04688419 -0.107074  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01419825 -0.02928257  0.03853776  0.04999452 -0.11104941]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.00579778 -0.03284442  0.04589803  0.05699099 -0.12481429]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00523932 -0.02207742  0.0276024   0.04764957 -0.0903129 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.00350635 -0.00963798  0.01908966  0.04023152 -0.10492092]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0113696  -0.01368201  0.02119029  0.028043   -0.09974267]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0053396  -0.01235087  0.02314757  0.03343382 -0.10450714]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 0.00320567 -0.0032459   0.02643087  0.03817954 -0.12136569]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00378746 -0.007284    0.02701108  0.03424508 -0.12025009]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00828665 -0.00515877  0.01534328  0.04947298 -0.12027837]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01664666 -0.00458242  0.01758377  0.06170163 -0.11637804]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00290551 -0.00184897  0.01538562  0.03560789 -0.10723241]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.01756489 -0.00203822  0.00884849  0.04165262 -0.10004733]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00017743 -0.01035388  0.01654074  0.05338454 -0.09580827]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00894316 -0.00897847  0.01742614  0.05519159 -0.0993351 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0124628  -0.00977386  0.01171905  0.05127037 -0.08856256]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01065332 -0.01802283  0.01163171  0.04798991 -0.0919109 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.00952526 -0.02855006  0.0108047   0.04872647 -0.08939816]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01311884 -0.03864817  0.0040069   0.04912224 -0.07955581]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01491177 -0.04630425  0.0170878   0.05403077 -0.09113081]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.02586986 -0.04620137  0.02201957  0.05224161 -0.09320273]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.03290325 -0.03443797  0.01457661  0.04492618 -0.11265755]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03920284 -0.03450334  0.01499409  0.03504623 -0.1133801 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.04483465 -0.02096278  0.02952939  0.03033047 -0.12134495]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03647653 -0.02479116  0.02116466  0.03791879 -0.12227384]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.05363045 -0.03316364  0.03944551  0.0248845  -0.09575744]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.04591319 -0.02995219  0.02966658  0.02913798 -0.09484881]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.05091932 -0.01523503  0.03446859  0.03976258 -0.11857461]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.05076017 -0.02512038  0.0294916   0.05388347 -0.11078148]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.05608916 -0.0297978   0.02183111  0.0521613  -0.10592704]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.06465706 -0.02427538  0.02463988  0.0316063  -0.0975989 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.05684835 -0.01221165  0.02397105  0.04919075 -0.11179064]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.04597807 -0.0200156   0.01417158  0.04789563 -0.10138136]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.06218476 -0.02578175  0.04761245  0.05290743 -0.09431396]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.04869447 -0.02726631  0.04487224  0.05808217 -0.10996267]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03817264 -0.02322705  0.04964286  0.06124521 -0.10031179]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.03769342 -0.00934414  0.06126992  0.05834786 -0.09579518]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03098516 -0.00949525  0.03962913  0.04832841 -0.08993418]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.04143285 -0.01168649  0.04276376  0.05121551 -0.10123555]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03606613 -0.01280961  0.03555534  0.04220076 -0.0995505 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02533038 -0.01010962  0.03115387  0.0494868  -0.10234909]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02056407 -0.01793471  0.05230135  0.05338236 -0.11081523]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01950724 -0.01609702  0.04770355  0.04971658 -0.10667209]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01828536 -0.00577056  0.03776006  0.0418319  -0.10178202]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02154087 -0.0121766   0.03985888  0.04519816 -0.10057377]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[ 0.00144807 -0.007597    0.03711426  0.04573793 -0.09791829]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 0.00042788 -0.00601226  0.03606091  0.04991609 -0.09337374]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00901073 -0.01659643  0.0389297   0.04843516 -0.09829524]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00236558 -0.00206645  0.04194941  0.0407559  -0.08645275]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.00892303 -0.01668646  0.04616546  0.03344696 -0.0760858 ]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00156792 -0.01755527  0.04438353  0.0196346  -0.0694792 ]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.002915   -0.03370753  0.0284734   0.02244987 -0.06816769]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[ 0.01100435 -0.0414632   0.02755627  0.03157357 -0.07831089]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.0064146  -0.02580264  0.03155084  0.04100841 -0.06864519]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00483951 -0.02743014  0.01818988  0.03562267 -0.0618411 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01326737 -0.03817377  0.02554004  0.02615456 -0.06589614]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00936639 -0.03591148  0.01636945  0.04311868 -0.07125338]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.01367607 -0.0338601   0.00912753  0.04570779 -0.05656177]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00658096 -0.03499736 -0.00013607  0.04951295 -0.04072612]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00137635 -0.05615886  0.0052919   0.06755468 -0.04649574]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.00057694 -0.05231778  0.00430711  0.06046739 -0.05544931]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.01137362 -0.0444806   0.01500454  0.05403808 -0.10043357]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Q-values: [[-0.01008387 -0.03294088 -0.00082961  0.04788658 -0.118284  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.00158546 -0.03941264  0.00048665  0.06381585 -0.12018751]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-1.0339109e-02 -4.4253666e-02  7.3157455e-05  5.6950953e-02\n",
      "  -1.0233615e-01]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01523375 -0.06512804  0.01026284  0.05250567 -0.10152071]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02986944 -0.0480708   0.01596996  0.05875473 -0.0961109 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.02633924 -0.04611009  0.02511341  0.05219899 -0.10156038]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03159999 -0.0584864   0.02712405  0.05444517 -0.11192027]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03035831 -0.05630475  0.01709487  0.05960364 -0.0974952 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03329322 -0.05104162  0.02896075  0.06398306 -0.1030161 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.04530777 -0.04671604  0.0157806   0.06831034 -0.09216075]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0367502  -0.06007274  0.01638067  0.06391621 -0.08379794]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.0421883  -0.06120332  0.02046493  0.06378969 -0.08554186]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01620386 -0.051797    0.02183225  0.0385018  -0.07329924]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01514232 -0.05712857  0.0198238   0.03031044 -0.06502936]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01330957 -0.05628742  0.02091414  0.02601981 -0.06548422]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.01934443 -0.0711837   0.02312758  0.04680739 -0.08309395]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01226598 -0.06317743  0.01503965  0.05157742 -0.07587197]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00484584 -0.06522032  0.02209443  0.07847876 -0.08712774]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00144862 -0.05573159  0.02714876  0.06840745 -0.08490272]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.00606428 -0.04854922  0.04108444  0.07545877 -0.12432141]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00324112 -0.05837368  0.04516198  0.09064645 -0.1278534 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00063076 -0.01427087  0.04375195  0.08494223 -0.09957491]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[-0.01098728 -0.01609352  0.05250844  0.07666184 -0.10566711]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[ 0.00759104 -0.02259008  0.04571015  0.06719546 -0.10230361]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.0169269  -0.02872222  0.0467994   0.06485108 -0.10554221]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.01968177 -0.02319442  0.03518767  0.05494013 -0.1063595 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.00239592 -0.01836043  0.04423352  0.05743275 -0.10125492]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[ 0.00151966 -0.01072838  0.0444448   0.0684295  -0.12011772]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.02070131 -0.00885054  0.03097207  0.0578238  -0.10002479]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[ 0.00105063 -0.01988166  0.03368361  0.04774564 -0.09744806]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.0194514  -0.01599056  0.03774443  0.05621547 -0.11019348]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00451538 -0.01891876  0.02909739  0.05615903 -0.10290474]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00643743 -0.0299711   0.0301077   0.0616502  -0.10516655]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.01736095 -0.02650717  0.01476263  0.05396908 -0.10795899]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02536516 -0.02035237  0.02002699  0.04828028 -0.10175578]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02499679 -0.03042349  0.03907277  0.05035522 -0.10753883]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00664617 -0.0341214   0.04568149  0.05916559 -0.10491836]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01111593 -0.02428915  0.05857953  0.05567556 -0.11028995]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03525192 -0.03535553  0.06247069  0.05481065 -0.11441834]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02639429 -0.03958399  0.06379063  0.06613366 -0.10650428]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.01619909 -0.03941223  0.05716631  0.05692637 -0.11428652]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01616541 -0.04336653  0.04426084  0.06059588 -0.11765296]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.01300195 -0.03964664  0.03694164  0.05411936 -0.12057298]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03290452 -0.04784878  0.05210476  0.05225537 -0.13705924]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02849198 -0.03752028  0.05385558  0.04527504 -0.12410586]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.04729296 -0.03733817  0.03889547  0.04573139 -0.12434145]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04938582 -0.02881657  0.02832389  0.05711391 -0.11857505]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.04310591 -0.03479476  0.00613609  0.05417403 -0.11219224]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.04907558 -0.02410794  0.00976956  0.03963605 -0.11410931]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04900851 -0.00649764  0.02098135  0.05097564 -0.10892875]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.03554385 -0.00654413  0.01100703  0.05713509 -0.10446558]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.05156312 -0.01165422  0.02235677  0.0571075  -0.09460494]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04221459 -0.01486859  0.03089607  0.05898422 -0.10711309]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02242251  0.00500968  0.04319554  0.04797712 -0.12451339]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01967712  0.01023182  0.04358191  0.0510686  -0.11504234]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0153719   0.00156037  0.05162377  0.05984891 -0.11972845]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00575938  0.00202627  0.05014703  0.04622414 -0.1142094 ]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01026866  0.00084482  0.03735242  0.04532682 -0.11598521]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[ 0.00407481 -0.01061888  0.02668903  0.05419911 -0.11498842]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00564599 -0.01025596  0.02916023  0.06506059 -0.12292238]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00602878 -0.01558632  0.0202673   0.06803647 -0.11657785]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00313635 -0.02583025  0.03302968  0.0614034  -0.11384392]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01976067 -0.03478335  0.04958914  0.05724265 -0.11438855]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00331603 -0.01996722  0.03985941  0.06530437 -0.11993943]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0023583  -0.01240697  0.02896482  0.0721359  -0.11591955]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00393207 -0.01815496  0.02408642  0.05725668 -0.11745143]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00157228 -0.01438828  0.01912243  0.0510645  -0.11220851]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00972658 -0.02041741  0.0298385   0.04603769 -0.10179837]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.00283441 -0.02892099  0.02927966  0.0584725  -0.11581498]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.01437485 -0.02317921  0.03819926  0.04808974 -0.11620298]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01604359 -0.0240945   0.04223616  0.04932453 -0.11425263]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00329785 -0.02581072  0.04595179  0.05852301 -0.09329467]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.0098748  -0.02523198  0.02606226  0.04510132 -0.08114947]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.0240408  -0.03296199  0.0157998   0.03923898 -0.08653419]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01822574 -0.03100636  0.01730939  0.04677258 -0.09855662]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.0199817  -0.00761005  0.02928523  0.03142562 -0.10460993]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00578934 -0.00190752  0.02193225  0.03364454 -0.08163992]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00316935 -0.02897543  0.02565653  0.03816267 -0.10006191]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00664629 -0.03901565  0.03297753  0.0299584  -0.10944939]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02264351 -0.04299128  0.04050235  0.03126131 -0.12664004]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01975848 -0.03725861  0.0195061   0.03106749 -0.14563155]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01748003 -0.04050671  0.02404077  0.04390618 -0.13486649]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01973053 -0.04741245  0.02097823  0.05041381 -0.12221677]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01909285 -0.04460304  0.02323488  0.03702876 -0.10936871]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03017374 -0.03566835  0.02504923  0.03030545 -0.10617117]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01276271 -0.03678106  0.02418291  0.02855729 -0.10207888]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01399972 -0.03949107  0.02640443  0.01870663 -0.11019723]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.03267106 -0.04581779  0.02672711  0.02316777 -0.1236624 ]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02652814 -0.04229465  0.02105612  0.0325752  -0.12355537]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02084568 -0.03920581  0.027929    0.03791979 -0.11199698]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.01458371 -0.05800325  0.03158246  0.04645871 -0.10970581]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02298417 -0.05766503  0.02243428  0.04300661 -0.09511555]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01266509 -0.04968078  0.02684012  0.0377729  -0.10282131]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.00747709 -0.03410121  0.02515317  0.03422698 -0.09546148]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01634693 -0.03359344  0.02193903  0.03532313 -0.0950861 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0121213  -0.04033823  0.02644799  0.03277291 -0.09932073]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00755022 -0.03559272  0.03659717  0.04317787 -0.10224505]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00470445 -0.04591402  0.02449108  0.05098503 -0.1125264 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.0111455  -0.03414097  0.03038844  0.04152397 -0.11048865]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01617677 -0.02804893  0.03371309  0.0439885  -0.11333089]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01228127 -0.030021    0.0417597   0.04997825 -0.12211407]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.01906612 -0.01917586  0.01925556  0.04592717 -0.09091396]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00525462 -0.00699048  0.01767045  0.03776763 -0.10425739]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00557329 -0.00971062  0.01967322  0.02617049 -0.10402785]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00356254 -0.00800948  0.01816831  0.03202797 -0.11146494]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.01269756 -0.00248565  0.02469417  0.03470795 -0.12645385]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00664589 -0.00879861  0.02472095  0.02908341 -0.12047878]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.01643371 -0.00828608  0.01390279  0.04517005 -0.11696051]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.02902429 -0.00651176  0.01582612  0.05252049 -0.10917281]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00687289 -0.00058887  0.01630923  0.02856581 -0.10286089]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.02506225 -0.00071583  0.01047169  0.0340473  -0.09642148]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00538204 -0.01161032  0.01966109  0.05010093 -0.09105741]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00263681 -0.00911844  0.02005778  0.053565   -0.09681522]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00813603 -0.00969797  0.01308726  0.04675348 -0.08570261]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00475285 -0.01749206  0.01231926  0.04850825 -0.09118243]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00623475 -0.02910671  0.0075865   0.04626309 -0.08870227]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.010427   -0.03961552  0.00144835  0.04543626 -0.07683434]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00914443 -0.04561987  0.01369159  0.04980755 -0.087633  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01908612 -0.04008387  0.01979084  0.04740985 -0.08994959]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02559082 -0.03262575  0.01080557  0.03838139 -0.11020759]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03165809 -0.03201174  0.01159436  0.02542561 -0.11315573]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.03662895 -0.01877885  0.02638647  0.02285257 -0.12010003]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.0373474  -0.02280444  0.01823884  0.03185843 -0.12272383]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.05029774 -0.03170804  0.03972579  0.01926292 -0.09467568]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.04029568 -0.02809291  0.03147193  0.02269205 -0.09462059]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[-0.0506662  -0.01071322  0.0382914   0.03510698 -0.11397386]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0510577  -0.02138791  0.03380756  0.04952049 -0.10845255]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.05303858 -0.02648692  0.02502888  0.0513762  -0.10723377]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.06175736 -0.01997643  0.02657133  0.03100878 -0.09918568]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.05211238 -0.00782227  0.02478365  0.04548677 -0.11368716]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.04450098 -0.01401204  0.01356869  0.04659828 -0.10390547]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.05828083 -0.01891856  0.04326491  0.04922752 -0.09617906]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.04510085 -0.01855183  0.04135088  0.05386375 -0.10900298]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03699296 -0.01571641  0.04429808  0.05528779 -0.10387511]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03678756 -0.00240774  0.05885441  0.05424273 -0.10014351]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.0348767  -0.00648913  0.03876313  0.04285377 -0.09400193]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[-0.03869661 -0.00618658  0.04155218  0.04772431 -0.10248134]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.03330744 -0.00586719  0.03141606  0.03640507 -0.09907428]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.02382891 -0.00620367  0.02912354  0.04351076 -0.10082641]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02135821 -0.01569513  0.04993872  0.05346409 -0.11259389]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01826728 -0.01275536  0.046262    0.04876503 -0.10667938]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0167589  -0.00143972  0.03047272  0.03890408 -0.09916829]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.02160984 -0.01134638  0.03522749  0.04085514 -0.09880625]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00128946 -0.00748948  0.03707828  0.04111356 -0.09738787]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.0017542  -0.00419542  0.03473601  0.04265946 -0.09180237]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.01104149 -0.01393187  0.03647529  0.04271014 -0.09169257]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.0061735   0.00185243  0.03886466  0.03536383 -0.0813947 ]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00798265 -0.01274074  0.04337414  0.02736485 -0.07215841]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.00051243 -0.01626237  0.03635365  0.01608377 -0.06802577]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00453066 -0.03098576  0.02219836  0.01989138 -0.06890822]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00685739 -0.03867038  0.02199065  0.02764702 -0.0787633 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00322483 -0.01992883  0.02788397  0.03520876 -0.06996534]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00303374 -0.02297944  0.01638697  0.02985944 -0.06415901]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01006017 -0.03365937  0.02346581  0.02127551 -0.06757345]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01113306 -0.03301836  0.01142297  0.03481137 -0.07040586]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00783742 -0.03144618  0.0056015   0.03706792 -0.05598321]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00148761 -0.03119297 -0.00461833  0.04725194 -0.03969641]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[ 0.00142165 -0.05528856  0.00149387  0.06680817 -0.04275606]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00286097 -0.05124613  0.00349155  0.0605608  -0.05248586]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00890401 -0.04656267  0.0140181   0.05073496 -0.09616881]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.00655481 -0.03610118  0.0004628   0.04755207 -0.11638616]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00052789 -0.04154392  0.00627923  0.06175281 -0.11982191]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01164757 -0.04361373  0.00348814  0.05187599 -0.10272584]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01225791 -0.06757527  0.01360847  0.04647769 -0.10240798]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02026657 -0.05144787  0.01994844  0.05474526 -0.09679963]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01835156 -0.04706515  0.03058584  0.04926388 -0.10403462]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02608484 -0.05877189  0.03708293  0.05001686 -0.11451382]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.02345248 -0.05114891  0.01712999  0.06025352 -0.10042565]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.0283107  -0.04850479  0.02617073  0.06252145 -0.10222986]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03728148 -0.04248422  0.01684631  0.06350891 -0.09311186]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03324074 -0.05360948  0.01451548  0.06000157 -0.08578981]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03935828 -0.05690747  0.02087719  0.0551347  -0.09064655]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01496806 -0.05193611  0.02127364  0.0310331  -0.07299912]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01611436 -0.05226431  0.01416691  0.03111356 -0.06296474]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01960081 -0.04945289  0.01732429  0.02426122 -0.06065727]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01872168 -0.06579304  0.01747612  0.04122498 -0.0767067 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.00420648 -0.05897391  0.01432025  0.04473829 -0.07414097]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00809812 -0.06041131  0.02740577  0.06883793 -0.08973167]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00742397 -0.05298915  0.02717696  0.06565958 -0.09099099]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.0059694  -0.0495315   0.03889196  0.07490287 -0.12408736]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.00161245 -0.05776311  0.05111943  0.08557614 -0.12704885]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.00148797 -0.01658724  0.04600238  0.08039451 -0.1019944 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01142563 -0.01854476  0.04915486  0.0760536  -0.10121012]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00689221 -0.02006817  0.03875523  0.06383619 -0.09572212]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01665799 -0.02725696  0.04154177  0.05941916 -0.09336571]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.01288089 -0.02067808  0.0291121   0.05240185 -0.10118654]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00085629 -0.01871053  0.03468602  0.05572388 -0.10202942]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00098686 -0.00989111  0.03743104  0.06642057 -0.11950804]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.01881267 -0.01018401  0.03290249  0.05469824 -0.10153527]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[ 0.00266219 -0.0274342   0.03182202  0.04589132 -0.09722687]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.01647292 -0.01763008  0.03460384  0.05475837 -0.10458399]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00061321 -0.02473564  0.02563043  0.05297421 -0.09563547]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00819671 -0.02671032  0.0226084   0.05886142 -0.09535873]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02251169 -0.02669551  0.0123433   0.05250978 -0.10059883]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.03317995 -0.02157818  0.01694591  0.05087873 -0.10052874]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.03135983 -0.03404414  0.03681544  0.05238278 -0.11142831]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00959914 -0.03699949  0.04377949  0.06516526 -0.10476397]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01197195 -0.02741916  0.05296766  0.05381411 -0.110599  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0312518  -0.03160038  0.0571554   0.05128115 -0.11103104]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.02814331 -0.03863057  0.05867608  0.0635289  -0.1065106 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02053204 -0.03784256  0.05189155  0.05518694 -0.11254776]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01454956 -0.04085336  0.04027803  0.06361888 -0.11656514]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.02202856 -0.04199169  0.03882261  0.05974612 -0.12291729]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03463743 -0.04758725  0.05232416  0.0559778  -0.1382905 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02998447 -0.04065347  0.04948809  0.04903278 -0.12383311]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.05203697 -0.0333055   0.04220005  0.04674705 -0.12653266]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.05369198 -0.03293243  0.02738807  0.05885339 -0.1287816 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[-0.04509571 -0.03567418  0.00287455  0.05932363 -0.12475535]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0486871  -0.02680885  0.01157093  0.04550319 -0.11991418]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04615267 -0.00966503  0.02710601  0.05609459 -0.11247261]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03343337 -0.00968716  0.01566252  0.06083028 -0.1098022 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04696358 -0.01380796  0.02914119  0.06094296 -0.09655979]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03772239 -0.01694882  0.02919783  0.05947606 -0.11196779]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02100539  0.00014468  0.04608553  0.04844369 -0.12718491]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01954277  0.00827524  0.04328357  0.05241842 -0.1200884 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01646425 -0.00108808  0.04869593  0.06133789 -0.12203159]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00585585  0.00339008  0.04925141  0.04987604 -0.11397011]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00897229  0.00375641  0.03556179  0.05235481 -0.11303386]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00155378 -0.00716466  0.02835627  0.05996856 -0.11199114]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01036963 -0.01143873  0.03401668  0.06669116 -0.12035362]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01101804 -0.01732089  0.02648433  0.06602897 -0.11349797]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01059387 -0.02324309  0.03448033  0.06175756 -0.11405525]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[-0.02372007 -0.03383854  0.04739194  0.05720638 -0.11561532]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Q-values: [[-0.00463368 -0.02358609  0.0412106   0.0698937  -0.1261618 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00069929 -0.01521299  0.03196289  0.07790582 -0.11665916]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.00919821 -0.01424694  0.0292324   0.06314133 -0.12417904]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.00060345 -0.01361057  0.02424678  0.05497352 -0.11443136]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00661843 -0.01971975  0.0331498   0.04873753 -0.10489227]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00348044 -0.02198582  0.03073734  0.05413628 -0.11362021]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.01505069 -0.02043434  0.03231905  0.04490466 -0.11230332]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Q-values: [[ 0.01708657 -0.02000008  0.03417455  0.05121669 -0.11151114]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.00114659 -0.02478964  0.04010231  0.06212455 -0.10104032]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00819739 -0.02504525  0.02824102  0.05491412 -0.09098747]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02373589 -0.03051362  0.02234212  0.04531569 -0.09770191]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01798247 -0.0260105   0.01897845  0.05048999 -0.10268479]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02109305 -0.01296881  0.02781048  0.03368122 -0.1046977 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00554062 -0.01142772  0.01896368  0.0311625  -0.08647789]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00100052 -0.0276      0.02051923  0.03771262 -0.10498266]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.0065715  -0.03667311  0.02806181  0.02914502 -0.11090361]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02168573 -0.03412203  0.03437617  0.03472266 -0.12647036]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01679915 -0.02727485  0.01344259  0.03219848 -0.14045863]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01930389 -0.03739475  0.02024971  0.04563033 -0.13376746]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02731638 -0.03790205  0.01728759  0.05195569 -0.11928204]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02610209 -0.04273184  0.02111558  0.04070497 -0.10989317]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.03979683 -0.03461306  0.01790435  0.03789014 -0.10849375]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01704254 -0.03606932  0.01787555  0.03515539 -0.10831551]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01743487 -0.04066233  0.01719411  0.02861143 -0.1191662 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Q-values: [[-0.03067098 -0.03965603  0.01666482  0.03544803 -0.13036121]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02594147 -0.0359608   0.01307061  0.04376263 -0.12746805]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.0236839  -0.03533335  0.0183591   0.04782058 -0.11426568]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01866868 -0.04982824  0.02647996  0.0571878  -0.11737283]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02196293 -0.04826383  0.01819205  0.04571948 -0.09841416]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01399137 -0.04078215  0.02355478  0.0408303  -0.1094899 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01038032 -0.02681707  0.01771823  0.03657388 -0.10456191]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.0199129  -0.0283049   0.01410865  0.03800813 -0.09875992]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01758444 -0.03426511  0.01953853  0.03450223 -0.10143366]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01106688 -0.03052788  0.0285563   0.04156378 -0.10093173]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.00899204 -0.04310673  0.02001738  0.05360333 -0.11400403]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00334485 -0.02796662  0.02330742  0.03972213 -0.10914371]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.0150353  -0.02281348  0.03565803  0.04549871 -0.1153807 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00853397 -0.02534677  0.03616557  0.05433999 -0.12832482]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.01152544 -0.01349866  0.0182026   0.04554173 -0.09605101]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00418938 -0.00723536  0.01333075  0.04112788 -0.1107154 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.0062599  -0.00541769  0.01855391  0.02934491 -0.10712644]]\n",
      "Action: 3, Reward: 0.0, Done: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[ 0.00056665 -0.00382145  0.01989278  0.03919128 -0.11426433]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00820562 -0.00110902  0.02528267  0.04200635 -0.13030283]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 0.00395565 -0.00366042  0.03009597  0.03772477 -0.12800606]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 1.73990540e-02 -1.10452165e-04  1.47129865e-02  4.76060957e-02\n",
      "  -1.20292075e-01]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 0.02879672  0.00100833  0.01452821  0.05850476 -0.11407263]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.0078451   0.01651196  0.01433005  0.0347417  -0.11102327]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[ 0.02630329  0.0103421   0.01393194  0.03941727 -0.10897737]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[ 0.0038058   0.00388471  0.01949125  0.05487031 -0.10118847]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00044252 -0.00148483  0.02516312  0.04994093 -0.10463573]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00394742 -0.00090687  0.0164767   0.0429988  -0.0874841 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.0002964  -0.00826556  0.01203518  0.04217158 -0.09475488]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00869635 -0.02290736  0.01125785  0.04535141 -0.09305517]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01563948 -0.02208652  0.00630012  0.0464495  -0.08837598]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.0157094  -0.02935869  0.02321305  0.05329721 -0.09948533]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02224227 -0.03132387  0.02485647  0.05435451 -0.10176253]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.02722006 -0.02213738  0.019977    0.04607194 -0.12074908]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03265095 -0.02347336  0.0136782   0.03153507 -0.11977396]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.04142078 -0.00341961  0.02475836  0.02710851 -0.12821957]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03471061 -0.0105256   0.01024275  0.03366621 -0.13080372]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.05734234 -0.02083701  0.03505676  0.01528506 -0.10592917]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04901652 -0.01488619  0.0295442   0.02201491 -0.10185925]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.0463178  -0.00760218  0.03546467  0.03512156 -0.11877019]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.0477981  -0.01656691  0.03153037  0.04855308 -0.10848128]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.04969303 -0.02598956  0.024602    0.04570341 -0.107506  ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.05947484 -0.01795596  0.02536243  0.02581097 -0.10388683]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-5.4496925e-02 -3.8765502e-05  2.5362276e-02  4.3149255e-02\n",
      "  -1.2194906e-01]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.04629026 -0.00787525  0.01447274  0.04551977 -0.11094024]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.05887001 -0.0155152   0.04476835  0.05095005 -0.10313006]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.04647037 -0.01760151  0.04465632  0.05751701 -0.11058777]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.03330998 -0.01767858  0.04933141  0.05830983 -0.09890792]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03246263 -0.00130417  0.05700397  0.05756363 -0.09346479]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02439451 -0.00172778  0.03645621  0.04714769 -0.08790224]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.03770376 -0.00410651  0.04001401  0.04726345 -0.10106066]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03324258 -0.00255919  0.03440125  0.0418556  -0.10020923]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.02675119 -0.00508537  0.02967935  0.0489322  -0.1019114 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.02165516 -0.01315892  0.04859327  0.05316527 -0.11512515]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.01926044 -0.01218356  0.04411324  0.05267799 -0.10938851]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.01712232 -0.00242403  0.03141344  0.04300726 -0.10283646]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02411925 -0.01277976  0.03880794  0.04485282 -0.10005002]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00169458 -0.0055882   0.03677155  0.04459625 -0.09314601]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-3.8841879e-04  6.6515007e-08  3.1293083e-02  4.7134779e-02\n",
      "  -9.3197770e-02]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.01075432 -0.01269207  0.03295964  0.04730044 -0.09008428]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 0.00348599  0.00273242  0.03441376  0.04353059 -0.08396005]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00876984 -0.01521227  0.04389818  0.03536783 -0.07890931]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[-0.00400774 -0.0228446   0.03779101  0.02182638 -0.07386535]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.005536   -0.03697737  0.02636585  0.0258829  -0.07620198]]\n",
      "Action: 2, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[ 0.00796432 -0.04198764  0.02676984  0.03371816 -0.08590186]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.00409253 -0.02533261  0.0298711   0.04195699 -0.06748486]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.00424072 -0.02470005  0.01280132  0.0321748  -0.05856949]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.01216108 -0.03499588  0.01217274  0.02685433 -0.06419464]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01072897 -0.0327963   0.00453589  0.04527101 -0.07036825]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.01218163 -0.02871706  0.00057836  0.04441493 -0.06218252]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.00547728 -0.03057898 -0.00490066  0.05169625 -0.04664602]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00273084 -0.05366127 -0.00288996  0.07175223 -0.05116233]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[ 0.00879651 -0.05098304 -0.00293516  0.06393328 -0.05809102]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00977319 -0.04537186  0.01473754  0.05110729 -0.09729278]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.00365582 -0.03100709 -0.00315632  0.04764338 -0.11556975]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.00290485 -0.04102424 -0.00134907  0.06360375 -0.11779713]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-1.09952465e-02 -4.42773625e-02  2.92241421e-05  5.39525636e-02\n",
      "  -9.55927297e-02]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01708739 -0.0610427   0.01117484  0.04369373 -0.09955401]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.0296761  -0.04851591  0.02066751  0.05584912 -0.10042112]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.0214541  -0.04537591  0.02642888  0.05081591 -0.10984903]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.02153675 -0.05784141  0.03005106  0.05270419 -0.12118213]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.02818865 -0.05113804  0.0180163   0.06070244 -0.10443137]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03267994 -0.04337646  0.024817    0.06447075 -0.10345592]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[-0.04062658 -0.04067953  0.01232032  0.06380017 -0.09407386]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.03684888 -0.05378511  0.00935566  0.05719411 -0.07985569]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[-0.04186482 -0.05513943  0.01818909  0.05458526 -0.09381731]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.01767597 -0.05540793  0.01679236  0.03318    -0.08137044]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.01736869 -0.04450037  0.00730487  0.03593734 -0.0716939 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[-0.01589659 -0.04117663  0.00988387  0.03336837 -0.06983934]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[-0.02155738 -0.05496656  0.0126692   0.05171239 -0.08979821]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Q-values: [[-0.00862907 -0.04912863  0.01256122  0.05356792 -0.0906631 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 0.01100689 -0.05563642  0.02686862  0.08182859 -0.10064185]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Q-values: [[ 0.01067014 -0.0502643   0.02820897  0.07659135 -0.09976964]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00889987 -0.04034453  0.04148468  0.07639744 -0.12799628]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[ 0.00532848 -0.04916398  0.04347217  0.09030757 -0.1287584 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Q-values: [[ 0.00491625 -0.01020393  0.0462491   0.07832644 -0.09860411]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Q-values: [[-0.00709193 -0.01558536  0.04477076  0.07247934 -0.0943919 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Q-values: [[ 0.00450912 -0.01486391  0.04339944  0.05919224 -0.0957235 ]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.01110731 -0.01831836  0.05161559  0.06031358 -0.10407744]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Q-values: [[ 0.01244534 -0.01152189  0.03930966  0.06001032 -0.10881162]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Q-values: [[-0.00315194 -0.00603879  0.04706543  0.05505959 -0.11150627]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Q-values: [[ 5.2950287e-05 -1.4947518e-03  4.2653214e-02  6.3215345e-02\n",
      "  -1.2433165e-01]]\n",
      "Action: 3, Reward: 0.0, Done: False\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Q-values: [[ 0.01795542  0.00141831  0.03606158  0.05273213 -0.10478333]]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "# Function to create the model for action decision\n",
    "def create_model(input_shape, action_space):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=input_shape),\n",
    "        Conv2D(64, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(action_space, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Preprocess the game state (image)\n",
    "def preprocess_state(state):\n",
    "    if isinstance(state, tuple) or isinstance(state, list):\n",
    "        state = state[0]\n",
    "    return np.array(state, dtype=np.float32) / 255.0\n",
    "\n",
    "# Function to choose an action based on the model's prediction\n",
    "def choose_action(state, model):\n",
    "    processed_state = preprocess_state(state)\n",
    "    q_values = model.predict(np.array([processed_state]))\n",
    "    print(\"Q-values:\", q_values)  # Diagnostic print to check Q-values\n",
    "    return np.argmax(q_values[0])\n",
    "\n",
    "# Initialize the game environment\n",
    "env = gym.make('ALE/Frogger-v5', render_mode='human')\n",
    "print(\"Action space:\", env.action_space)  # Diagnostic print to check the action space\n",
    "\n",
    "model = create_model((210, 160, 3), env.action_space.n)  # Setup the neural network model\n",
    "\n",
    "state = env.reset()\n",
    "print(\"Initial state structure:\", state)  # Print the initial state to understand its structure\n",
    "\n",
    "# Assuming the actual game state is the first element if it's a tuple or list\n",
    "if isinstance(state, (tuple, list)):\n",
    "    state = state[0]\n",
    "\n",
    "# Main game loop with diagnostics\n",
    "done = False\n",
    "while not done:\n",
    "    action = choose_action(state, model)  # Determine action\n",
    "    outputs = env.step(action)\n",
    "    state = outputs[0]  # Update state assuming state is the first element\n",
    "    reward = outputs[1]  # Extract reward\n",
    "    done = outputs[2]  # Check if the game is finished\n",
    "    info = outputs[3] if len(outputs) > 3 else {}  # Info is the fourth element if it exists\n",
    "    env.render()\n",
    "    print(f\"Action: {action}, Reward: {reward}, Done: {done}\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = env.step(action)  # Get all outputs from the environment step\n",
    "state = outputs[0]  # State is always the first element\n",
    "reward = outputs[1]  # Reward is always the second element\n",
    "done = outputs[2]  # Done flag is always the third element\n",
    "info = outputs[3] if len(outputs) > 3 else {}  # Info is the fourth element if it exists, else empty dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
